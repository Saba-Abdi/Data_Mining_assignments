# -*- coding: utf-8 -*-
"""HW1-Group1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18T4DutW1tHmt1lbfSju5CLtCZR_uMXzE

# Prob. 1 #

#### Check the pdf file. Analysis is in that file because it did not need python codes.

# Prob. 2#
"""

# Firstly, we import the libraries we need.
import pandas as pd
import numpy as np

tips = pd.read_csv("tips.csv") # reading the data. Note that the data is uploaded in the google colab file.
tips_df = tips.copy()
tips.head() # in order to know the data and its attributes better, we look at its 5 first rows.

tips.describe() # We also use this method to get more familiar with our numeric attributes.

"""#### Question 1"""

# Firstly, we calculate required measures for total_bill attribute.
total_bill_mean = tips_df["total_bill"].mean()
total_bill_median = tips_df["total_bill"].median()
total_bill_mode = tips_df["total_bill"].mode()[0]
total_bill_range = tips_df["total_bill"].max() - tips_df["total_bill"].min()  # There is not a specific function for range, so we use max - min.
total_bill_var = tips_df["total_bill"].var()
total_bill_std = tips_df["total_bill"].std()

# Then, we calculate required measures for total_bill attribute.
tip_mean = tips_df["tip"].mean()
tip_median = tips_df["tip"].median()
tip_mode = tips_df["tip"].mode()[0]
tip_range = tips_df["tip"].max() - tips_df["total_bill"].min()
tip_var = tips_df["tip"].var()
tip_std = tips_df["tip"].std()

# In order to show it in a neater way, we put all the calculated measures into a new dataframe.
data = {
    'measures': ['mean', 'median', 'mode', 'range', 'variance', 'standard deviation'],
    'total_bill': [total_bill_mean,total_bill_median, total_bill_mode, total_bill_range, total_bill_var, total_bill_std],
    'tip': [tip_mean, tip_median,tip_mode, tip_range, tip_var, tip_std]
}

StatisticsMeasures_df = pd.DataFrame(data)
StatisticsMeasures_df.set_index('measures', inplace=True)
StatisticsMeasures_df

"""#### Question 2"""

# Runnig a test to see if skewness exists.
from scipy.stats import skewtest
stat, p_value = skewtest(tips_df["tip"])
print("Skewness stat: ", stat)
print("P-value: ", p_value)

"""#### Question 3"""

import matplotlib.pyplot as plt
import seaborn as sns

# depicting distribution of the attribute using histogram
plt.figure(figsize=(6, 4))
sns.histplot(tips_df['total_bill'], bins=20, kde=True)
plt.title("Distibutaion(Histogram) of Total Bill")
plt.xlabel("total bill")
plt.ylabel("frequency")
plt.show()

# Runninga test to see if the datas of the attribute follow normal distribution.
from scipy.stats import shapiro
stat, p_value = shapiro(tips_df["total_bill"])
print("Shapiro stat: ", stat)
print("P-value: ", p_value)

"""#### Question 4"""

# depicting box plot of tip attribute
plt.figure(figsize=(6, 4))
sns.boxplot(x=tips_df["tip"])
plt.title("Boxplot of tip")
plt.show()

# Calculate the IQR and bounds
tip_Q1 = tips_df["tip"].quantile(0.25)
tip_Q3 = tips_df["tip"].quantile(0.75)
tip_IQR = tip_Q3 - tip_Q1
tip_lower_bound = tip_Q1 - 1.5 * tip_IQR
tip_upper_bound = tip_Q3 + 1.5 * tip_IQR

# Identify outliers
tip_outliers = tips_df[(tips_df["tip"] < tip_lower_bound) | (tips_df["tip"] > tip_upper_bound)]
tip_outliers

"""#### Question 5"""

# First we import the library which is needed for QQplot.
import statsmodels.api as sm

# Then we draw the plot.
plt.figure(figsize=(6, 4))
sm.qqplot(tips_df['total_bill'], line='s')
plt.title("Q-Q Plot of Total Bill")
plt.show()

"""#### Question 6"""

# depicting box plot of total_bill attribute for further insights
plt.figure(figsize=(6, 4))
sns.boxplot(x=tips_df["total_bill"])
plt.title("Boxplot of Total Bill")
plt.show()

# calculate IQR and bounds
total_bill_Q1 = tips_df['total_bill'].quantile(0.25)
total_bill_Q3 = tips_df['total_bill'].quantile(0.75)
total_bill_IQR = total_bill_Q3 - total_bill_Q1
total_bill_lower_bound = total_bill_Q1 - 1.5 * total_bill_IQR
total_bill_upper_bound = total_bill_Q3 + 1.5 * total_bill_IQR

# Identify outliers
total_bill_outliers = tips_df[(tips_df['total_bill'] > total_bill_upper_bound) | (tips_df['total_bill'] < total_bill_lower_bound)]
total_bill_outliers

"""# Prob. 3 #



"""

import pandas as pd
import numpy as np
from scipy.stats import zscore

df = pd.read_csv("physical_characteristics.csv")

"""#### Question 1"""

selected_columns = ["Age", "Weight (kg)", "Height (cm)"]
# euclidean distance calculation
row1 = df.loc[95, selected_columns].values
row2 = df.loc[4, selected_columns].values

euclidean_distance = np.linalg.norm(row1 - row2)
print("Euclidean Distance:", euclidean_distance)

"""#### Question 2"""

selected_columns = ["Age", "Weight (kg)", "Height (cm)"]
df[selected_columns] = df[selected_columns].apply(zscore)

# standardize selected columns

columns = ["PersonID","Age", "Weight (kg)", "Height (cm)"]
print(df.loc[[95, 4], columns])

# euclidean distance calculation
row1 = df.loc[95, selected_columns].values
row2 = df.loc[4, selected_columns].values

euclidean_distance = np.linalg.norm(row1 - row2)
print("Euclidean Distance:", euclidean_distance)

"""#### Question 3"""

# First we get all unique datas in given columns.
EyeColor_unique_values = df['Eye Color'].unique()
EyeColor_unique_values

HairColor_unique_values = df['Hair Color'].unique()
HairColor_unique_values

BodyType_unique_values = df['Body Type'].unique()
BodyType_unique_values

# By using OneHotEncoder, we convert nominal variables to binary ones.
# person id = 5
eye_5_array = np.array([0,0,0,0,1])
hair_5_array = np.array([1,0,0,0,0])
body_5_array = np.array([0,1,0,0])

d_2 = np.array([0,0,0,0,1,1,0,0,0,0,0,1,0,0])
d_2

# By using OneHotEncoder, we convert nominal variables to binary ones.
# person id = 96
eye_96_array = np.array([0,1,0,0,0])
hair_96_array = np.array([1,0,0,0,0])
body_96_array = np.array([0,1,0,0])

d_1 = np.array([0,1,0,0,0,1,0,0,0,0,0,1,0,0])
d_1

"""#### Question 5"""

# First we write the rows
record_96 = {"Average", "Black", "Blue"}
record_5 = {"Average", "Black", "Green"}

# Then we caclcute their intersection and union
intersection = record_96.intersection(record_5)
union = record_96.union(record_5)

# Then we calculate the similarity ans dissimilarity.
jaccard_similarity = len(intersection) / len(union)
jaccard_distance = 1 - jaccard_similarity

print("Jaccard Similarity:", jaccard_similarity)
print("Jaccard Distance:", jaccard_distance)

"""# Prob. 4#

#### Question 1
"""

import pandas as pd

#First we read the data.
df = pd.read_csv("physical_characteristics.csv")

# Then using pandas' methods, we create contigency table.
contingency_table = pd.crosstab(df['Body Type'], df['Gender'])
contingency_table.loc['Total'] = contingency_table.sum(axis=0)
contingency_table['Total'] = contingency_table.sum(axis=1)

print(contingency_table)

# In order to implement the test, we import needed library.
from scipy.stats import chi2_contingency

# test implementation
chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)
print(f"Chi-Square Statistic: {chi2_stat}")
print(f"P-Value: {p_value}")
print(f"Degrees of Freedom: {dof}")
print("Expected Frequencies Table:")
print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))